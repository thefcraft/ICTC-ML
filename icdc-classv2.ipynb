{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1700 entries, 0 to 1699\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ben     1700 non-null   object\n",
      " 1   guj     1700 non-null   object\n",
      " 2   hin     1700 non-null   object\n",
      " 3   kan     1700 non-null   object\n",
      " 4   mal     1700 non-null   object\n",
      " 5   ori     1700 non-null   object\n",
      " 6   pan     1700 non-null   object\n",
      " 7   tam     1700 non-null   object\n",
      " 8   tel     1700 non-null   object\n",
      " 9   urd     1700 non-null   object\n",
      " 10  eng     1700 non-null   object\n",
      "dtypes: object(11)\n",
      "memory usage: 146.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('icdc\\\\train.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1700/1700 [00:00<00:00, 2806.92it/s]\n"
     ]
    }
   ],
   "source": [
    "allTexts = ''\n",
    "for i in tqdm(range(df.__len__())):\n",
    "    allTexts += ''.join(df.iloc[i]).lower().replace('–','').replace('$','').replace('&','').replace('[','').replace(']',''\n",
    "                                            ).replace('“','').replace('”','').replace('=','').replace('৷','').replace('`','').replace('ؑ', '').replace('}',''\n",
    "                                            ).replace('-', '').replace('*', '').replace('^', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hinglish_res = Counter(allTexts)\n",
    "# sorted(list(dict(hinglish_res).items()), key = lambda x: x[1], reverse=True)\n",
    "charsVocab = list(dict(hinglish_res).items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63, 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAD_NULL = '-'\n",
    "PAD_START = '*'\n",
    "PAD_END = '^'\n",
    "\n",
    "vocab = [PAD_NULL, PAD_START, PAD_END]+[i[0] for i in charsVocab]\n",
    "\n",
    "IDX_PAD_NULL = vocab.index(PAD_NULL)\n",
    "\n",
    "len(vocab), IDX_PAD_NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau#, StepLR, ExponentialLR\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  1],\n",
       "        [14, 19],\n",
       "        [ 4, 13],\n",
       "        [ 4, 17],\n",
       "        [12,  3],\n",
       "        [ 0, 36],\n",
       "        [ 0, 36],\n",
       "        [ 0, 36],\n",
       "        [ 0, 14]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_extraToken(texts, startToken=True, endToken=True):\n",
    "    if startToken and endToken: return [PAD_START+text+PAD_END for text in texts]\n",
    "    elif startToken: return [PAD_START+text for text in texts]\n",
    "    elif endToken: return [text+PAD_END for text in texts]\n",
    "    else: return texts\n",
    "\n",
    "def remove_extraToken(texts:list[str])->list[str]:\n",
    "    return [text.lower().replace('–','').replace('$','').replace('&','').replace('[','').replace(']',''\n",
    "                                            ).replace('“','').replace('”','').replace('=','').replace('৷','').replace('`','').replace('ؑ', '').replace('}',''\n",
    "                                            ).replace(PAD_START, '').replace(PAD_END, '').replace(PAD_NULL, '')\n",
    "            for text in texts]\n",
    "\n",
    "def preprocesser(texts: list[str], prePadding=False, startToken=True, endToken=True, batch_first=False):\n",
    "    texts = add_extraToken(remove_extraToken(texts), startToken, endToken)\n",
    "    text_ints = [[vocab.index(c) for c in text if c in vocab] for text in texts]\n",
    "    # Apply pre-padding to each sequence\n",
    "    if prePadding:\n",
    "        max_length = max(len(seq) for seq in text_ints)\n",
    "        padded_seqs = pad_sequence([torch.cat([torch.tensor([IDX_PAD_NULL]*(max_length - len(seq)), dtype=torch.int64), torch.LongTensor(seq)]) for seq in text_ints], batch_first=True)\n",
    "    else:\n",
    "        padded_seqs = pad_sequence([torch.LongTensor(seq) for seq in text_ints], batch_first=True, padding_value=IDX_PAD_NULL)\n",
    "    \n",
    "    return padded_seqs if batch_first else padded_seqs.T\n",
    "\n",
    "\n",
    "preprocesser(['hiir', 'laksfffh'], startToken=True, endToken=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, batch_size=64):\n",
    "        dataset = []\n",
    "\n",
    "        for y, col in enumerate(df.columns):\n",
    "            for i in range(df[col].__len__()):\n",
    "                text = df[col].iloc[i].lower().replace('–','').replace('$','').replace('&','').replace('[','').replace(']',''\n",
    "                                            ).replace('“','').replace('”','').replace('=','').replace('৷','').replace('`','').replace('ؑ', '').replace('}',''\n",
    "                                            ).replace(PAD_START, '').replace(PAD_END, '').replace(PAD_NULL, '')\n",
    "                dataset.append((text, y, df[col].iloc[i]))\n",
    "        \n",
    "        dataset.sort(key=lambda x: len(x[0]))\n",
    "        \n",
    "        self.batched = []\n",
    "        for i in range(0, len(dataset), batch_size): self.batched.append(self.custom_collate_fn(dataset[i:i+batch_size]))\n",
    "    \n",
    "    def custom_collate_fn(self, batch):\n",
    "        x = []\n",
    "        y = []\n",
    "        real = []\n",
    "        for ix, iy, ireal in batch:\n",
    "            x.append(ix)\n",
    "            y.append(iy)\n",
    "            real.append(ireal)\n",
    "        return preprocesser(x), F.one_hot(torch.tensor(y), num_classes=11).to(torch.float32), real\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batched)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Return a single sequence and its label\n",
    "        return self.batched[idx]\n",
    "\n",
    "# Create a DataLoader with batch size 64\n",
    "custom_dataset = CustomDataset(batch_size=64)  # Create an instance of the custom dataset\n",
    "data_loader = DataLoader(custom_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "# Iterate through the DataLoader\n",
    "for batch in data_loader:\n",
    "    sequences, labels, _ = batch\n",
    "    sequences.squeeze_(0)\n",
    "    labels.squeeze_(0)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_size, num_layers, vocab_size, p=0, num_classes=11):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, dropout=p, bidirectional=False) \n",
    "        # self.fc1 = nn.Linear(hidden_size, hidden_size*2)\n",
    "        # self.fc2 = nn.Linear(hidden_size*2, num_classes)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (sequencen x batch_size)\n",
    "        x = self.dropout(self.embedding(x)) # (sequencen x batch_size x embedding_dim)\n",
    "        outputs, (hidden, cell) = self.lstm(x) # (sequencen x batch_size x hidden_size), ((num_layers x batch_size x hidden_size), (num_layers x batch_size x hidden_size))\n",
    "        return self.fc(outputs[-1])\n",
    "        # x = F.relu(self.fc1(outputs[-1]))\n",
    "        # return self.fc2(x)\n",
    "\n",
    "\n",
    "# Create an LSTM model\n",
    "# model = Encoder(50, 128, 2, vocab_size=len(vocab)).to(DEVICE)\n",
    "# x = sequences\n",
    "# y = labels\n",
    "# print(x.shape)\n",
    "# model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "LR = 0.001\n",
    "EMBEDDING_SIZE = 50\n",
    "HIDDEN_SIZE = 128\n",
    "NUM_LAYERS = 2\n",
    "P = 0.5\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "TRAIN_SIZE = .8\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, math\n",
    "\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def accuracy(model, data_loader):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Disable gradient computation during inference\n",
    "    for (sequences, labels, _) in data_loader: # test_loader\n",
    "        sequences = sequences.squeeze(0).to(DEVICE)\n",
    "        labels = labels.squeeze(0).to(DEVICE).argmax(dim=1)\n",
    "        # Forward pass\n",
    "        predicted = model(sequences).argmax(dim=1)\n",
    "            \n",
    "        # Count total number of labels\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        # Count number of correct predictions\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    model.train()\n",
    "    # Calculate accuracy\n",
    "    return 100 * correct / total\n",
    "    # print('Accuracy: {:.2f}%'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader with batch size 64\n",
    "custom_dataset = CustomDataset(BATCH_SIZE)\n",
    "\n",
    "train_size = int(0.8 * len(custom_dataset))\n",
    "test_size = len(custom_dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(custom_dataset, [train_size, test_size], generator=torch.Generator().manual_seed(SEED))\n",
    "\n",
    "# Create data loaders for train and test sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "model = Encoder(EMBEDDING_SIZE, HIDDEN_SIZE, NUM_LAYERS, vocab_size=len(vocab), p=P, num_classes=11).to(device=DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = ReduceLROnPlateau(optimizer, patience=10)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "model.load_state_dict(torch.load('models_icdc\\\\gru.model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0m 1s] Train Epoch: [0/100] \tLoss: 410.15 Test Loss: 279.86\n",
      "[0m 3s] Train Epoch: [1/100] \tLoss: 275.44 Test Loss: 207.66\n",
      "[0m 5s] Train Epoch: [2/100] \tLoss: 243.43 Test Loss: 182.21\n",
      "[0m 6s] Train Epoch: [3/100] \tLoss: 205.02 Test Loss: 157.45\n",
      "[0m 8s] Train Epoch: [4/100] \tLoss: 178.23 Test Loss: 146.56\n",
      "[0m 10s] Train Epoch: [5/100] \tLoss: 154.93 Test Loss: 150.73\n",
      "[0m 12s] Train Epoch: [6/100] \tLoss: 164.74 Test Loss: 144.49\n",
      "[0m 13s] Train Epoch: [7/100] \tLoss: 139.35 Test Loss: 112.31\n",
      "[0m 15s] Train Epoch: [8/100] \tLoss: 121.24 Test Loss: 97.51\n",
      "[0m 17s] Train Epoch: [9/100] \tLoss: 111.74 Test Loss: 93.02\n",
      "[0m 18s] Train Epoch: [10/100] \tLoss: 103.48 Test Loss: 90.00\n",
      "[0m 20s] Train Epoch: [11/100] \tLoss: 93.87 Test Loss: 76.19\n",
      "[0m 21s] Train Epoch: [12/100] \tLoss: 89.59 Test Loss: 69.93\n",
      "[0m 23s] Train Epoch: [13/100] \tLoss: 81.07 Test Loss: 65.05\n",
      "[0m 25s] Train Epoch: [14/100] \tLoss: 76.18 Test Loss: 66.12\n",
      "[0m 26s] Train Epoch: [15/100] \tLoss: 71.25 Test Loss: 61.14\n",
      "[0m 28s] Train Epoch: [16/100] \tLoss: 68.26 Test Loss: 67.16\n",
      "[0m 29s] Train Epoch: [17/100] \tLoss: 63.22 Test Loss: 51.78\n",
      "[0m 31s] Train Epoch: [18/100] \tLoss: 60.55 Test Loss: 55.04\n",
      "[0m 33s] Train Epoch: [19/100] \tLoss: 54.68 Test Loss: 51.86\n",
      "[0m 34s] Train Epoch: [20/100] \tLoss: 50.96 Test Loss: 53.98\n",
      "[0m 36s] Train Epoch: [21/100] \tLoss: 47.76 Test Loss: 48.31\n",
      "[0m 38s] Train Epoch: [22/100] \tLoss: 43.58 Test Loss: 47.74\n",
      "[0m 39s] Train Epoch: [23/100] \tLoss: 43.39 Test Loss: 45.47\n",
      "[0m 41s] Train Epoch: [24/100] \tLoss: 42.22 Test Loss: 47.81\n",
      "[0m 42s] Train Epoch: [25/100] \tLoss: 38.99 Test Loss: 45.10\n",
      "[0m 44s] Train Epoch: [26/100] \tLoss: 37.89 Test Loss: 38.79\n",
      "[0m 45s] Train Epoch: [27/100] \tLoss: 34.68 Test Loss: 40.33\n",
      "[0m 47s] Train Epoch: [28/100] \tLoss: 33.35 Test Loss: 43.35\n",
      "[0m 49s] Train Epoch: [29/100] \tLoss: 32.91 Test Loss: 40.95\n",
      "[0m 50s] Train Epoch: [30/100] \tLoss: 30.40 Test Loss: 38.65\n",
      "[0m 52s] Train Epoch: [31/100] \tLoss: 28.93 Test Loss: 48.81\n",
      "[0m 54s] Train Epoch: [32/100] \tLoss: 27.99 Test Loss: 37.45\n",
      "[0m 55s] Train Epoch: [33/100] \tLoss: 26.47 Test Loss: 37.17\n",
      "[0m 57s] Train Epoch: [34/100] \tLoss: 25.81 Test Loss: 42.34\n",
      "[0m 58s] Train Epoch: [35/100] \tLoss: 25.13 Test Loss: 41.78\n",
      "[1m 0s] Train Epoch: [36/100] \tLoss: 24.74 Test Loss: 36.19\n",
      "[1m 2s] Train Epoch: [37/100] \tLoss: 22.98 Test Loss: 39.09\n",
      "[1m 3s] Train Epoch: [38/100] \tLoss: 21.06 Test Loss: 39.21\n",
      "[1m 5s] Train Epoch: [39/100] \tLoss: 20.15 Test Loss: 37.39\n",
      "[1m 6s] Train Epoch: [40/100] \tLoss: 18.84 Test Loss: 37.55\n",
      "[1m 8s] Train Epoch: [41/100] \tLoss: 20.71 Test Loss: 39.57\n",
      "[1m 9s] Train Epoch: [42/100] \tLoss: 19.85 Test Loss: 39.54\n",
      "[1m 11s] Train Epoch: [43/100] \tLoss: 18.87 Test Loss: 37.84\n",
      "[1m 13s] Train Epoch: [44/100] \tLoss: 20.56 Test Loss: 39.87\n",
      "[1m 14s] Train Epoch: [45/100] \tLoss: 18.27 Test Loss: 37.32\n",
      "[1m 16s] Train Epoch: [46/100] \tLoss: 15.86 Test Loss: 40.21\n",
      "[1m 17s] Train Epoch: [47/100] \tLoss: 15.68 Test Loss: 39.66\n",
      "[1m 19s] Train Epoch: [48/100] \tLoss: 12.93 Test Loss: 36.63\n",
      "[1m 20s] Train Epoch: [49/100] \tLoss: 11.95 Test Loss: 36.32\n",
      "[1m 22s] Train Epoch: [50/100] \tLoss: 11.07 Test Loss: 36.17\n",
      "[1m 23s] Train Epoch: [51/100] \tLoss: 10.94 Test Loss: 36.43\n",
      "[1m 25s] Train Epoch: [52/100] \tLoss: 10.78 Test Loss: 36.67\n",
      "[1m 26s] Train Epoch: [53/100] \tLoss: 11.27 Test Loss: 35.64\n",
      "[1m 28s] Train Epoch: [54/100] \tLoss: 10.79 Test Loss: 36.19\n",
      "[1m 30s] Train Epoch: [55/100] \tLoss: 9.08 Test Loss: 35.78\n",
      "[1m 31s] Train Epoch: [56/100] \tLoss: 10.09 Test Loss: 35.95\n",
      "[1m 33s] Train Epoch: [57/100] \tLoss: 10.27 Test Loss: 35.58\n",
      "[1m 35s] Train Epoch: [58/100] \tLoss: 9.78 Test Loss: 37.64\n",
      "[1m 36s] Train Epoch: [59/100] \tLoss: 9.07 Test Loss: 37.01\n",
      "[1m 38s] Train Epoch: [60/100] \tLoss: 9.66 Test Loss: 37.77\n",
      "[1m 39s] Train Epoch: [61/100] \tLoss: 9.41 Test Loss: 36.25\n",
      "[1m 41s] Train Epoch: [62/100] \tLoss: 9.53 Test Loss: 36.74\n",
      "[1m 43s] Train Epoch: [63/100] \tLoss: 8.46 Test Loss: 36.84\n",
      "[1m 44s] Train Epoch: [64/100] \tLoss: 8.71 Test Loss: 35.75\n",
      "[1m 46s] Train Epoch: [65/100] \tLoss: 9.20 Test Loss: 36.41\n",
      "[1m 47s] Train Epoch: [66/100] \tLoss: 8.26 Test Loss: 35.54\n",
      "[1m 49s] Train Epoch: [67/100] \tLoss: 8.67 Test Loss: 36.04\n",
      "[1m 51s] Train Epoch: [68/100] \tLoss: 7.25 Test Loss: 36.26\n",
      "[1m 52s] Train Epoch: [69/100] \tLoss: 7.88 Test Loss: 36.88\n",
      "[1m 54s] Train Epoch: [70/100] \tLoss: 8.51 Test Loss: 36.62\n",
      "[1m 56s] Train Epoch: [71/100] \tLoss: 7.65 Test Loss: 36.56\n",
      "[1m 57s] Train Epoch: [72/100] \tLoss: 7.94 Test Loss: 37.35\n",
      "[1m 59s] Train Epoch: [73/100] \tLoss: 7.54 Test Loss: 36.80\n",
      "[2m 0s] Train Epoch: [74/100] \tLoss: 7.99 Test Loss: 37.90\n",
      "[2m 2s] Train Epoch: [75/100] \tLoss: 7.70 Test Loss: 36.33\n",
      "[2m 4s] Train Epoch: [76/100] \tLoss: 7.54 Test Loss: 35.29\n",
      "[2m 5s] Train Epoch: [77/100] \tLoss: 7.01 Test Loss: 36.29\n",
      "[2m 7s] Train Epoch: [78/100] \tLoss: 7.62 Test Loss: 36.48\n",
      "[2m 8s] Train Epoch: [79/100] \tLoss: 7.36 Test Loss: 37.11\n",
      "[2m 10s] Train Epoch: [80/100] \tLoss: 6.91 Test Loss: 37.41\n",
      "[2m 12s] Train Epoch: [81/100] \tLoss: 6.94 Test Loss: 36.14\n",
      "[2m 13s] Train Epoch: [82/100] \tLoss: 6.87 Test Loss: 36.10\n",
      "[2m 15s] Train Epoch: [83/100] \tLoss: 6.62 Test Loss: 36.99\n",
      "[2m 16s] Train Epoch: [84/100] \tLoss: 6.14 Test Loss: 37.71\n",
      "[2m 18s] Train Epoch: [85/100] \tLoss: 7.26 Test Loss: 37.27\n",
      "[2m 19s] Train Epoch: [86/100] \tLoss: 6.58 Test Loss: 37.12\n",
      "[2m 21s] Train Epoch: [87/100] \tLoss: 6.70 Test Loss: 36.88\n",
      "[2m 22s] Train Epoch: [88/100] \tLoss: 6.35 Test Loss: 36.97\n",
      "[2m 24s] Train Epoch: [89/100] \tLoss: 6.55 Test Loss: 37.09\n",
      "[2m 26s] Train Epoch: [90/100] \tLoss: 6.94 Test Loss: 37.24\n",
      "[2m 27s] Train Epoch: [91/100] \tLoss: 6.86 Test Loss: 37.20\n",
      "[2m 29s] Train Epoch: [92/100] \tLoss: 6.27 Test Loss: 37.09\n",
      "[2m 30s] Train Epoch: [93/100] \tLoss: 6.46 Test Loss: 37.25\n",
      "[2m 32s] Train Epoch: [94/100] \tLoss: 6.12 Test Loss: 37.26\n",
      "[2m 34s] Train Epoch: [95/100] \tLoss: 6.34 Test Loss: 37.09\n",
      "[2m 35s] Train Epoch: [96/100] \tLoss: 6.05 Test Loss: 37.18\n",
      "[2m 37s] Train Epoch: [97/100] \tLoss: 6.64 Test Loss: 37.24\n",
      "[2m 39s] Train Epoch: [98/100] \tLoss: 6.69 Test Loss: 37.14\n",
      "[2m 40s] Train Epoch: [99/100] \tLoss: 6.04 Test Loss: 37.17\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "start = time.time()\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    # Iterate through the DataLoader\n",
    "    model.train()\n",
    "    for (sequences, labels, _) in train_loader:\n",
    "        sequences = sequences.squeeze(0).to(DEVICE)\n",
    "        labels = labels.squeeze(0).to(DEVICE)\n",
    "        \n",
    "        output = model(sequences)\n",
    "        \n",
    "        loss = criterion(output, labels)\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Validation phase\n",
    "    valid_loss = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for (sequences, labels, _) in test_loader:\n",
    "            sequences = sequences.squeeze(0).to(DEVICE)\n",
    "            labels = labels.squeeze(0).to(DEVICE)\n",
    "        \n",
    "            output = model(sequences)\n",
    "        \n",
    "            loss = criterion(output, labels)\n",
    "            valid_loss += loss.item()\n",
    "        \n",
    "    print('[{}] Train Epoch: [{}/{}] \\tLoss: {:.2f} Test Loss: {:.2f}'.format(\n",
    "            time_since(start), epoch, EPOCHS,\n",
    "            total_loss, valid_loss*len(train_loader)/len(test_loader)))\n",
    "    \n",
    "    scheduler.step(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 'models_icdc\\\\gru.model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 99.94%\n",
      "Test Accuracy: 96.03%\n"
     ]
    }
   ],
   "source": [
    "print('Train Accuracy: {:.2f}%'.format(accuracy(model, train_loader)))\n",
    "print('Test Accuracy: {:.2f}%'.format(accuracy(model, test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTHER BEST MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB # best\n",
    "from sklearn.svm import SVC # best\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = [], []\n",
    "for (_, labels, real) in train_loader:\n",
    "    X_train += [i[0] for i in real]\n",
    "    y_train += labels.squeeze(0).argmax(dim=1).numpy().tolist()\n",
    "    \n",
    "X_test, y_test = [], []\n",
    "for (_, labels, real) in test_loader:\n",
    "    X_test += [i[0] for i in real]\n",
    "    y_test += labels.squeeze(0).argmax(dim=1).numpy().tolist()\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "X_test_vect = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9679555084745762\n"
     ]
    }
   ],
   "source": [
    "# load\n",
    "with open('models_icdc\\\\lr.model.pkl', 'rb') as f:\n",
    "    lr_classifier = pickle.load(f)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, lr_classifier.predict(X_test_vect)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9679555084745762\n"
     ]
    }
   ],
   "source": [
    "lr_classifier = LogisticRegression(max_iter=300)\n",
    "lr_classifier.fit(X_train_vect, y_train)\n",
    "pred_lr = lr_classifier.predict(X_test_vect)\n",
    "\n",
    "with open('models_icdc\\\\lr.model.pkl','wb') as f: pickle.dump(lr_classifier,f)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9769597457627118\n"
     ]
    }
   ],
   "source": [
    "# load\n",
    "with open('models_icdc\\\\nb.model.pkl', 'rb') as f:\n",
    "    nb_classifier = pickle.load(f)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, nb_classifier.predict(X_test_vect)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9769597457627118\n"
     ]
    }
   ],
   "source": [
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train_vect, y_train)\n",
    "pred_nb = nb_classifier.predict(X_test_vect)\n",
    "with open('models_icdc\\\\nb.model.pkl','wb') as f: pickle.dump(nb_classifier,f)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier F1 score:  0.9245796017973961\n"
     ]
    }
   ],
   "source": [
    "# load\n",
    "with open('models_icdc\\\\rf.model.pkl', 'rb') as f:\n",
    "    rf_classifier = pickle.load(f)\n",
    "print(\"RandomForestClassifier F1 score: \", f1_score(y_test, rf_classifier.predict(X_test_vect), average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier F1 score:  0.9245796017973961\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier()\n",
    "rf_classifier.fit(X_train_vect, y_train)\n",
    "pred_rf = rf_classifier.predict(X_test_vect)\n",
    "with open('models_icdc\\\\rf.model.pkl','wb') as f: pickle.dump(rf_classifier,f)\n",
    "print(\"RandomForestClassifier F1 score: \", f1_score(y_test, pred_rf, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier F1 score:  0.9020493021687092\n"
     ]
    }
   ],
   "source": [
    "# load\n",
    "with open('models_icdc\\\\xgb.model.pkl', 'rb') as f:\n",
    "    xgb_classifier = pickle.load(f)\n",
    "print(\"XGBClassifier F1 score: \", f1_score(y_test, xgb_classifier.predict(X_test_vect), average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier F1 score:  0.9020493021687092\n"
     ]
    }
   ],
   "source": [
    "xgb_classifier = XGBClassifier()\n",
    "xgb_classifier.fit(X_train_vect, y_train)\n",
    "pred_xgb = xgb_classifier.predict(X_test_vect)\n",
    "with open('models_icdc\\\\xgb.model.pkl','wb') as f: pickle.dump(xgb_classifier,f)\n",
    "print(\"XGBClassifier F1 score: \", f1_score(y_test, pred_xgb, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9690148305084746\n"
     ]
    }
   ],
   "source": [
    "# load\n",
    "with open('models_icdc\\\\svm.model.pkl', 'rb') as f:\n",
    "    svm_model = pickle.load(f)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, svm_model.predict(X_test_vect)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9690148305084746\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(kernel='linear', probability=True)\n",
    "svm_model.fit(X_train_vect, y_train)\n",
    "pred_SVM = svm_model.predict(X_test_vect)\n",
    "with open('models_icdc\\\\svm.model.pkl','wb') as f: pickle.dump(svm_model,f)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_SVM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.848781779661017\n"
     ]
    }
   ],
   "source": [
    "# load\n",
    "with open('models_icdc\\\\dtc.model.pkl', 'rb') as f:\n",
    "    DTC = pickle.load(f)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, DTC.predict(X_test_vect)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.848781779661017\n"
     ]
    }
   ],
   "source": [
    "DTC=DecisionTreeClassifier()\n",
    "DTC.fit(X_train_vect,y_train)\n",
    "pred_DTC=DTC.predict(X_test_vect)\n",
    "with open('models_icdc\\\\dtc.model.pkl','wb') as f: pickle.dump(DTC,f)\n",
    "print(\"Accuracy:\", accuracy_score(y_test,pred_DTC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU\n",
    "model.eval()\n",
    "test_gru = []\n",
    "pred_gru = []\n",
    "with torch.no_grad():    \n",
    "    for (sequences, labels, _) in test_loader: # test_loader\n",
    "        sequences = sequences.squeeze(0).to(DEVICE)\n",
    "        labels = labels.squeeze(0).to(DEVICE).argmax(dim=1)\n",
    "        # Forward pass\n",
    "        predicted = model(sequences).argmax(dim=1)\n",
    "        test_gru.append(labels.cpu().numpy())\n",
    "        pred_gru.append(predicted.cpu().numpy())\n",
    "model.train()\n",
    "test_gru = np.concatenate(test_gru, axis = 0)\n",
    "pred_gru = np.concatenate(pred_gru, axis = 0)\n",
    "\n",
    "\n",
    "def model_predict(X):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs =  model(preprocesser(X).to(DEVICE)).cpu().numpy()\n",
    "    model.train()\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1 score:  0.9680349579067693\n",
      "Naive Bayes F1 score:  0.9767645507998631\n",
      "SVM F1 score:  0.9691697667143868\n",
      "Decission Tree Classifier F1 score:  0.8520085722918403\n",
      "GRU F1 score:  0.9603549941415811\n",
      "\n",
      "Logistic Regression Accuracy:  0.9679555084745762\n",
      "Naive Bayes Accuracy:  0.9769597457627118\n",
      "SVM Accuracy:  0.9690148305084746\n",
      "Decission Tree Classifier Accuracy:  0.848781779661017\n",
      "GRU Accuracy:  0.9602754237288136\n",
      "\n",
      "Logistic Regression MSE:  0.816207627118644\n",
      "Naive Bayes MSE:  0.5238347457627118\n",
      "SVM MSE:  0.7915783898305084\n",
      "Decission Tree Classifier MSE:  4.112023305084746\n",
      "GRU MSE:  0.8601694915254238\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression F1 score: \", f1_score(y_test, pred_lr,average='weighted'))\n",
    "print(\"Naive Bayes F1 score: \", f1_score(y_test, pred_nb,average='weighted'))\n",
    "print(\"SVM F1 score: \", f1_score(y_test, pred_SVM,average='weighted'))\n",
    "print(\"Decission Tree Classifier F1 score: \",f1_score(y_test, pred_DTC,average='weighted'))\n",
    "print(\"GRU F1 score: \", f1_score(test_gru, pred_gru,average='weighted'))\n",
    "print()\n",
    "print(\"Logistic Regression Accuracy: \", accuracy_score(y_test, pred_lr))\n",
    "print(\"Naive Bayes Accuracy: \", accuracy_score(y_test, pred_nb))\n",
    "print(\"SVM Accuracy: \", accuracy_score(y_test, pred_SVM))\n",
    "print(\"Decission Tree Classifier Accuracy: \",accuracy_score(y_test, pred_DTC))\n",
    "print(\"GRU Accuracy: \", accuracy_score(test_gru, pred_gru))\n",
    "print()\n",
    "print(\"Logistic Regression MSE: \", mean_squared_error(y_test, pred_lr))\n",
    "print(\"Naive Bayes MSE: \", mean_squared_error(y_test, pred_nb))\n",
    "print(\"SVM MSE: \", mean_squared_error(y_test, pred_SVM))\n",
    "print(\"Decission Tree Classifier MSE: \",mean_squared_error(y_test, pred_DTC))\n",
    "print(\"GRU MSE: \", mean_squared_error(test_gru, pred_gru))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZE and MAKE between 0 and 1\n",
    "def prob(arr:np.ndarray, gap_adjuster:int=3)->np.ndarray:\n",
    "    if len(arr.shape) == 1:\n",
    "        arr = (arr-arr.min())/(arr.max()-arr.min())\n",
    "        arr = arr**gap_adjuster\n",
    "        return arr/arr.sum()\n",
    "    else:\n",
    "        arr = (arr-arr.min(axis=1).reshape(-1, 1))/(arr.max(axis=1)-arr.min(axis=1)).reshape(-1, 1)\n",
    "        arr = arr**gap_adjuster\n",
    "        return arr/arr.sum(axis=1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.0020 0.0058 0.0000',\n",
       " '0.0018 0.0057 0.0000',\n",
       " '0.9682 0.8851 1.0000',\n",
       " '0.0022 0.0036 0.0000',\n",
       " '0.0028 0.0047 0.0000',\n",
       " '0.0028 0.0064 0.0000',\n",
       " '0.0013 0.0054 0.0000',\n",
       " '0.0026 0.0048 0.0000',\n",
       " '0.0043 0.0067 0.0000',\n",
       " '0.0093 0.0609 0.0000',\n",
       " '0.0025 0.0108 0.0000']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\"{:.4f} {:.4f} {:.4f}\".format(i1, i2, i3) for i1, i2, i3 in zip(\n",
    "        lr_classifier.predict_proba(X_test_vect[:1])[0], \n",
    "        nb_classifier.predict_proba(X_test_vect[:1])[0],\n",
    "        svm_model.predict_proba(X_test_vect[:1])[0]\n",
    "    )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    tmp = model(sequences).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.0011 -3.1708',\n",
       " '0.0005 -3.7718',\n",
       " '0.0286 1.6531',\n",
       " '0.0000 -5.4118',\n",
       " '0.0028 -2.2800',\n",
       " '0.0145 0.1661',\n",
       " '0.9081 17.5087',\n",
       " '0.0000 -5.6665',\n",
       " '0.0140 0.1032',\n",
       " '0.0263 1.4525',\n",
       " '0.0040 -1.8767']"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\"{:.4f} {:.4f}\".format(i1, i2) for i1, i2 in zip(prob(tmp[0]).tolist(), tmp[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ben']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def emsemble_infer_v1(texts:str|list[str], printable=False):\n",
    "    if isinstance(texts, str): texts = [texts]\n",
    "    output = (\n",
    "        lr_classifier.predict_proba(vectorizer.transform(texts)) +\n",
    "        nb_classifier.predict_proba(vectorizer.transform(texts)) + \n",
    "        svm_model.predict_proba(vectorizer.transform(texts)) + \n",
    "        prob(model_predict(texts))\n",
    "    ).argmax(axis=1)\n",
    "    if printable:\n",
    "        return [['ben', 'guj', 'hin', 'kan', 'mal', 'ori', 'pan', 'tam', 'tel', 'urd', 'eng'][i] for i in output.tolist()]\n",
    "    else:\n",
    "        return output\n",
    "    \n",
    "    \n",
    "emsemble_infer_v1('alute masala makhie, fetano basena chubie nie dubo tele bhaja yatakshan na bhalo kare bhaja hachche, tiri kara has maharashtrer ei suswadu o janapriya khavarer pad.', \n",
    "                  printable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:06<00:00,  8.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.9846273291282108\n",
      "Accuracy:  0.9846398305084746\n",
      "MSE:  0.4907309322033898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred_emsemble_v1 = []\n",
    "for i in tqdm(range(0, len(X_test), 64)):\n",
    "    pred_emsemble_v1.append(emsemble_infer_v1(X_test[i:i+64]))\n",
    "\n",
    "pred_emsemble_v1 = np.concatenate(pred_emsemble_v1, axis = 0)\n",
    "\n",
    "print(\"F1 score: \", f1_score(y_test, pred_emsemble_v1,average='weighted'))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, pred_emsemble_v1))\n",
    "print(\"MSE: \", mean_squared_error(y_test, pred_emsemble_v1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emsemble_infer_v2(texts:str|list[str], printable=False):\n",
    "    if isinstance(texts, str): texts = [texts]\n",
    "    output = (\n",
    "        prob(lr_classifier.predict_proba(vectorizer.transform(texts)), gap_adjuster=1) + \n",
    "        prob(nb_classifier.predict_proba(vectorizer.transform(texts)), gap_adjuster=1) + \n",
    "        prob(svm_model.predict_proba(vectorizer.transform(texts)), gap_adjuster=1) + \n",
    "        prob(model_predict(texts), gap_adjuster=6)\n",
    "    ).argmax(axis=1)\n",
    "    if printable:\n",
    "        return [['ben', 'guj', 'hin', 'kan', 'mal', 'ori', 'pan', 'tam', 'tel', 'urd', 'eng'][i] for i in output.tolist()]\n",
    "    else:\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:06<00:00,  8.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.9878127820296828\n",
      "Accuracy:  0.9878177966101694\n",
      "MSE:  0.3877118644067797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred_emsemble_v2 = []\n",
    "for i in tqdm(range(0, len(X_test), 64)):\n",
    "    pred_emsemble_v2.append(emsemble_infer_v2(X_test[i:i+64]))\n",
    "\n",
    "pred_emsemble_v2 = np.concatenate(pred_emsemble_v2, axis = 0)\n",
    "\n",
    "print(\"F1 score: \", f1_score(y_test, pred_emsemble_v2, average='weighted'))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, pred_emsemble_v2))\n",
    "print(\"MSE: \", mean_squared_error(y_test, pred_emsemble_v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ben', 'hin', 'eng']"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emsemble_infer_v2([\"m mase kono ullekhayogya tapapravaher dasha anubhav kara yyani.\", 'tum kya kar rahe ho yaar?', 'can you do somethig for me?'], printable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class(idx): return ['ben', 'guj', 'hin', 'kan', 'mal', 'ori', 'pan', 'tam', 'tel', 'urd', 'eng'][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: `urd` but model gives `hin`\n",
      "is film ne kai ewardiz bhi jite.\n",
      "\n",
      "Error: `urd` but model gives `hin`\n",
      "tum mushkil se padhaai karte ho.\n",
      "\n",
      "Error: `urd` but model gives `hin`\n",
      "kam iz kam 15 se 20 kaam ke din.\n",
      "\n",
      "Error: `urd` but model gives `hin`\n",
      "vaise aap ko kaise patta chalaa?\n",
      "\n",
      "Error: `urd` but model gives `hin`\n",
      "apne ghar par raho, aaraam karo.\n",
      "\n",
      "Error: `urd` but model gives `hin`\n",
      "mujhe maaf kar deejiye madam.\n",
      "\n",
      "Error: `hin` but model gives `urd`\n",
      "mujhe pichhali class main bataai gai kuch nadiyaan yaad hai.\n",
      "\n",
      "Error: `kan` but model gives `ori`\n",
      "bill andre durvani bill, athwa karent bill athwa nirin bill.\n",
      "\n",
      "Error: `ori` but model gives `guj`\n",
      "tame kouthiki yaythil?\n",
      "\n",
      "Error: `urd` but model gives `hin`\n",
      "aaj ke liye itanaa hi.\n",
      "\n",
      "Error: `mal` but model gives `tam`\n",
      "indyakark 35 rupyu videshik 550 rupee.\n",
      "\n",
      "Error: `pan` but model gives `urd`\n",
      "awchha, kallh 14 april hai hain naame?\n",
      "\n",
      "Error: `tel` but model gives `ori`\n",
      "i madhya evaina bike ridlaki valelava?\n",
      "\n",
      "Error: `hin` but model gives `urd`\n",
      "aap jis dish kii baat kar rahi hai, use peetha yaa kholaa peetha kehete hai.\n",
      "\n",
      "Error: `hin` but model gives `urd`\n",
      "compozit package main is sab ke saath jaigarh or royal senotafa shaamil hai.\n",
      "\n",
      "Error: `hin` but model gives `urd`\n",
      "mauridon kii ek mahila marbaut hui hai, sokhna magat dyope, jinhone apane pita kaa pad viraasat main paaya tha.\n",
      "\n",
      "Error: `kan` but model gives `ben`\n",
      "halo, nivu trinity praiamik shaley arts tichar srimati radhika avra?\n",
      "\n",
      "Error: `mal` but model gives `tam`\n",
      "sindagi na milengi dobara, del chahta hai ocaillae entu road trippa?\n",
      "\n",
      "Error: `tam` but model gives `eng`\n",
      "bengal chemicals and barmasuticals niruvanum calcutta palkalixkatin vediiyal perasiriuran bhi.chi. re avarkalal niruvappattatu.\n",
      "\n",
      "Error: `guj` but model gives `tam`\n",
      "baas, tyano anand man.\n",
      "\n",
      "Error: `guj` but model gives `ben`\n",
      "suprabhat, kumari lia!\n",
      "\n",
      "Error: `kan` but model gives `mal`\n",
      "nale ambedkar jayanti!\n",
      "\n",
      "Error: `mal` but model gives `eng`\n",
      "halo naman, it rahula.\n",
      "\n",
      "Error: `urd` but model gives `hin`\n",
      "tum kaise ho?\n",
      "\n",
      "Error: `urd` but model gives `pan`\n",
      "oh, thik hai.\n",
      "\n",
      "Error: `urd` but model gives `hin`\n",
      "bilkul madam.\n",
      "\n",
      "Error: `kan` but model gives `ben`\n",
      "goa, maccha!!!\n",
      "\n",
      "Error: `mal` but model gives `kan`\n",
      "parade tuirio?\n",
      "\n",
      "Error: `ori` but model gives `guj`\n",
      "aa' o basipad.\n",
      "\n",
      "Error: `hin` but model gives `urd`\n",
      "main paisa nikaalane ke baad khate main bachi rakam kaise jaan saktaa hum?\n",
      "\n",
      "Error: `tel` but model gives `ben`\n",
      "halo, trinity elementry skull art tichar raadhik garena?\n",
      "\n",
      "Error: `hin` but model gives `ben`\n",
      "chalo baccho, kaam shuru karen.\n",
      "\n",
      "Error: `kan` but model gives `guj`\n",
      "andre 5 gantegella mane bidbeku\n",
      "\n",
      "Error: `urd` but model gives `hin`\n",
      "tum lavola college gaye the, hai naa?\n",
      "\n",
      "Error: `urd` but model gives `hin`\n",
      "bilkul. brah meharabaani kar deejiye.\n",
      "\n",
      "Error: `hin` but model gives `urd`\n",
      "is bhram ko hataane ke liye log aparigrah kii pratigya lete hai or aatma kii purnataa ko jaan pate hai.\n",
      "\n",
      "Error: `mal` but model gives `tel`\n",
      "shubhadinam, suhritte, artists galeriai swagata!\n",
      "\n",
      "Error: `mal` but model gives `kan`\n",
      "bi.si. rantanutandietenne karutapetunnatu sanyasimathangu chityagruatelu ulppetunnatu, shantiyu pavitrathyu kinimanothukunnatumay aake 29 baddhashilaguhal ajantaguhalute bhag.\n",
      "\n",
      "Error: `urd` but model gives `hin`\n",
      "1960 ke olympic khelon main 400 meter kafainal?\n",
      "\n",
      "Error: `hin` but model gives `urd`\n",
      "1829 main haija ural parvat ke dakshini chor tak fail gaya tha.\n",
      "\n",
      "Error: `ben` but model gives `tam`\n",
      "dinkatak vishram nite balette doctor.\n",
      "\n",
      "Error: `guj` but model gives `ben`\n",
      "card pahochadwama ketlo samay lagfee?\n",
      "\n",
      "Error: `urd` but model gives `hin`\n",
      "vahaan bas lutf induz ho.\n",
      "\n",
      "Error: `urd` but model gives `hin`\n",
      "kuch aisa jese mishroom brown rice yaa chicken canva biryani.\n",
      "\n",
      "Error: `tel` but model gives `ben`\n",
      "thanks ra, na garle frand ki maticchanu.\n",
      "\n",
      "Error: `hin` but model gives `urd`\n",
      "online aavedan karne kii antim taarikh 31.01.2020 thi.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for inp, real, pred in zip(X_test, y_test, pred_emsemble_v2):\n",
    "    if real != pred:\n",
    "        # if get_class(real) not in ['hin', 'urd'] and get_class(pred) not in ['hin', 'urd']:\n",
    "        print(f\"Error: `{get_class(real)}` but model gives `{get_class(pred)}`\")\n",
    "        print(inp)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
